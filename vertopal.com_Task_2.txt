

Task 2

Credit / Home Loans - AutoML vs Bespoke ML

Standard Bank is embracing the digital transformation wave and intends
to use new and exciting technologies to give their customers a complete
set of services from the convenience of their mobile devices. As
Africaâ€™s biggest lender by assets, the bank aims to improve the current
process in which potential borrowers apply for a home loan. The current
process involves loan officers having to manually process home loan
applications. This process takes 2 to 3 days to process upon which the
applicant will receive communication on whether or not they have been
granted the loan for the requested amount. To improve the process
Standard Bank wants to make use of machine learning to assess the credit
worthiness of an applicant by implementing a model that will predict if
the potential borrower will default on his/her loan or not, and do this
such that the applicant receives a response immediately after completing
their application.

You will be required to follow the data science lifecycle to fulfill the
objective. The data science lifecycle
(https://www.datascience-pm.com/crisp-dm-2/) includes:

-   Business Understanding
-   Data Understanding
-   Data Preparation
-   Modelling
-   Evaluation
-   Deployment.

You now know the CRoss Industry Standard Process for Data Mining
(CRISP-DM), have an idea of the business needs and objectivess, and
understand the data. Next is the tedious task of preparing the data for
modeling, modeling and evaluating the model. Luckily, just like EDA the
first of the two phases can be automated. But also, just like EDA this
is not always best.

In this task you will be get a taste of AutoML and Bespoke ML. In the
notebook we make use of the library auto-sklearn/autosklearn
(https://www.automl.org/automl/auto-sklearn/) for AutoML and sklearn for
ML. We will use train one machine for the traditional approach and you
will be required to change this model to any of the models that exist in
sklearn. The model we will train will be a Logistic Regression. Parts of
the data preparation will be omitted for you to do, but we will provide
hints to lead you in the right direction.

The data provided can be found in the Resources folder as well as
(https://www.kaggle.com/datasets/altruistdelhite04/loan-prediction-problem-dataset).

-   train will serve as the historical dataset that the model will be
    trained on and,
-   test will serve as unseen data we will predict on, i.e. new
    ('future') applicants.

Part One

There are many AutoEDA Python libraries out there which include:

-   dtale (https://dtale.readthedocs.io/en/latest/)
-   pandas profiling
    (https://pandas-profiling.ydata.ai/docs/master/index.html)
-   autoviz (https://readthedocs.org/projects/autoviz/)
-   sweetviz (https://pypi.org/project/sweetviz/)

and many more. In this task we will use Sweetviz.. You may be required
to use bespoke EDA methods.

The Home Loans Department manager wants to know the following:

1.  An overview of the data. (HINT: Provide the number of records,
    fields and their data types. Do for both).

2.  What data quality issues exist in both train and test? (HINT:
    Comment any missing values and duplicates)

3.  How do the the loan statuses compare? i.e. what is the distrubition
    of each?

4.  How do women and men compare when it comes to defaulting on loans in
    the historical dataset?

5.  How many of the loan applicants have dependents based on the
    historical dataset?

6.  How do the incomes of those who are employed compare to those who
    are self employed based on the historical dataset?

7.  Are applicants with a credit history more likely to default than
    those who do not have one?

8.  Is there a correlation between the applicant's income and the loan
    amount they applied for?

Part Two

Run the AutoML section and then fill in code for the traditional ML
section for the the omitted cells.

Please note that the notebook you submit must include the analysis you
did in Task 2.

Import Libraries

    # !pip install sweetviz 
    #uncomment the above if you need to install the library 
    # !pip install auto-sklearn
    #uncomment the above if you need to install the library 

    # !pip install --upgrade scipy

    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    import sweetviz 
    import autosklearn.classification
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import accuracy_score, confusion_matrix
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.impute import SimpleImputer

Import Datasets

    train = pd.read_csv('train.csv')
    test = pd.read_csv('test.csv')

Part One

EDA

    train.head()

        Loan_ID Gender Married Dependents     Education Self_Employed  \
    0  LP001002   Male      No          0      Graduate            No   
    1  LP001003   Male     Yes          1      Graduate            No   
    2  LP001005   Male     Yes          0      Graduate           Yes   
    3  LP001006   Male     Yes          0  Not Graduate            No   
    4  LP001008   Male      No          0      Graduate            No   

       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \
    0             5849                0.0         NaN             360.0   
    1             4583             1508.0       128.0             360.0   
    2             3000                0.0        66.0             360.0   
    3             2583             2358.0       120.0             360.0   
    4             6000                0.0       141.0             360.0   

       Credit_History Property_Area Loan_Status  
    0             1.0         Urban           Y  
    1             1.0         Rural           N  
    2             1.0         Urban           Y  
    3             1.0         Urban           Y  
    4             1.0         Urban           Y  

    test.head()

        Loan_ID Gender Married Dependents     Education Self_Employed  \
    0  LP001015   Male     Yes          0      Graduate            No   
    1  LP001022   Male     Yes          1      Graduate            No   
    2  LP001031   Male     Yes          2      Graduate            No   
    3  LP001035   Male     Yes          2      Graduate            No   
    4  LP001051   Male      No          0  Not Graduate            No   

       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \
    0             5720                  0       110.0             360.0   
    1             3076               1500       126.0             360.0   
    2             5000               1800       208.0             360.0   
    3             2340               2546       100.0             360.0   
    4             3276                  0        78.0             360.0   

       Credit_History Property_Area  
    0             1.0         Urban  
    1             1.0         Urban  
    2             1.0         Urban  
    3             NaN         Urban  
    4             1.0         Urban  

    # we concat for easy analysis
    n = train.shape[0] # we set this to be able to separate the
    df = pd.concat([train, test], axis=0)
    df.head()

        Loan_ID Gender Married Dependents     Education Self_Employed  \
    0  LP001002   Male      No          0      Graduate            No   
    1  LP001003   Male     Yes          1      Graduate            No   
    2  LP001005   Male     Yes          0      Graduate           Yes   
    3  LP001006   Male     Yes          0  Not Graduate            No   
    4  LP001008   Male      No          0      Graduate            No   

       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \
    0             5849                0.0         NaN             360.0   
    1             4583             1508.0       128.0             360.0   
    2             3000                0.0        66.0             360.0   
    3             2583             2358.0       120.0             360.0   
    4             6000                0.0       141.0             360.0   

       Credit_History Property_Area Loan_Status  
    0             1.0         Urban           Y  
    1             1.0         Rural           N  
    2             1.0         Urban           Y  
    3             1.0         Urban           Y  
    4             1.0         Urban           Y  

Sweetviz

    autoEDA = sweetviz.analyze(train)
    autoEDA.show_notebook()

    {"version_major":2,"version_minor":0,"model_id":"771ab61cc9c249888e762c99ccc875d3"}

    <IPython.core.display.HTML object>

Your Own EDA

Your anwers:

1.  
2.  
3.  
4.  
5.  
6.  
7.  
8.  
9.  
10. 

Part Two

Auto ML wth autosklearn

    # Matrix of features

    X = train[['Gender',
    'Married',
    'Dependents',
    'Education',
    'Self_Employed',
    'ApplicantIncome',
    'CoapplicantIncome',
    'LoanAmount',
    'Loan_Amount_Term',
    'Credit_History',
    'Property_Area']]

    # convert string(text) to categorical
    X['Gender'] = X['Gender'].astype('category')
    X['Married'] = X['Married'].astype('category')
    X['Education'] = X['Education'].astype('category')
    X['Dependents'] = X['Dependents'].astype('category')
    X['Self_Employed'] = X['Self_Employed'].astype('category')
    X['Property_Area'] = X['Property_Area'].astype('category')


    # label encode target
    y = train['Loan_Status'].map({'N':0,'Y':1}).astype(int)


    # # train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      app.launch_new_instance()
    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead

    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

    # train
    autoML = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=2*30, per_run_time_limit=30, n_jobs=8) # imposing a 1 minute time limit on this
    autoML.fit(X_train, y_train)

    # predict
    predictions_autoML = autoML.predict(X_test)

    print('Model Accuracy:', accuracy_score(predictions_autoML, y_test))

    Model Accuracy: 0.7886178861788617

    print(confusion_matrix(predictions_autoML, y_test))

    [[18  1]
     [25 79]]

Bespoke ML sklearn

Data Preparation

    # Matrix of features

    df = train[['Education',
    'Property_Area']]

    ### Include Numerical Features Here ###
    ### Handle Missing Values Here ###
    ### Scale Here ###


    # label encode target
    y = train['Loan_Status'].map({'N':0,'Y':1}).astype(int)

    # # encode with get dummies
    X = pd.DataFrame(df, columns=df.columns)
    X = pd.get_dummies(X, drop_first=True)

    # # train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # some classifiers you can pick from (remember to import)
    import sklearn
    classifiers = sklearn.utils.all_estimators(type_filter=None)
    for name, class_ in classifiers:
        if hasattr(class_, 'predict_proba'):
            print(name)

    AdaBoostClassifier
    BaggingClassifier
    BayesianGaussianMixture
    BernoulliNB
    CalibratedClassifierCV
    CategoricalNB
    ClassifierChain
    ComplementNB
    DecisionTreeClassifier
    DummyClassifier
    ExtraTreeClassifier
    ExtraTreesClassifier
    GaussianMixture
    GaussianNB
    GaussianProcessClassifier
    GradientBoostingClassifier
    GridSearchCV
    HalvingGridSearchCV
    HalvingRandomSearchCV
    HistGradientBoostingClassifier
    KNeighborsClassifier
    LabelPropagation
    LabelSpreading
    LinearDiscriminantAnalysis
    LogisticRegression
    LogisticRegressionCV
    MLPClassifier
    MultiOutputClassifier
    MultinomialNB
    NuSVC
    OneVsRestClassifier
    Pipeline
    QuadraticDiscriminantAnalysis
    RFE
    RFECV
    RadiusNeighborsClassifier
    RandomForestClassifier
    RandomizedSearchCV
    SGDClassifier
    SVC
    SelfTrainingClassifier
    StackingClassifier
    VotingClassifier

    # train
    clf = LogisticRegression() #change model here
    clf.fit(X_train, y_train)

    # predict
    predictions_clf = clf.predict(X_test)

    print('Model Accuracy:', accuracy_score(predictions_clf, y_test))

    Model Accuracy: 0.6504065040650406

    print(confusion_matrix(predictions_clf, y_test))

    [[ 0  0]
     [43 80]]
